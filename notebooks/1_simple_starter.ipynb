{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Simple Starter: Prompt/Question Answering via Ollama API\n\n**Purpose**: Show how to send a prompt to an LLM running via Ollama and get back text.\n\n**Dependencies**: `requests`\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import requests\nimport json\n\n# use simulate=True to bypass actual API calls\nsimulate = True"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def call_ollama(prompt, model='llama3'):\n    \"\"\"Send a prompt to a local Ollama model and return the text.\"\"\"\n    if simulate:\n        # simulated response as if from the API\n        return {'response': 'Paris'}\n    data = {'model': model, 'prompt': prompt}\n    r = requests.post('http://localhost:11434/api/generate', json=data, timeout=60)\n    r.raise_for_status()\n    return r.json()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "prompt = 'What is the capital of France?'\nresult = call_ollama(prompt)\nprint('Answer:', result['response'])"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
