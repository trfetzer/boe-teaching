{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Embedding Illustration with mxbai-embed-large\n\n**Purpose**: Obtain embeddings for a few words and project them to 2D.\n\n**Dependencies**: `openai`, `numpy`, `matplotlib`\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom openai import OpenAI\nclient = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "words = ['man', 'woman', 'king', 'queen']\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def embed(text):\n    response = client.embeddings.create(model=\"mxbai-embed-large\", input=text)\n    return np.array(response.data[0].embedding)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "vecs = np.vstack([embed(w) for w in words])\n# simple 2D projection\nproj = vecs[:, :2]\nfor w, p in zip(words, proj):\n    plt.scatter(p[0], p[1])\n    plt.text(p[0]+0.02, p[1]+0.02, w)\nplt.show()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from numpy.linalg import norm\n\ndef cosine(u,v):\n    return np.dot(u,v)/(norm(u)*norm(v))\n\nprint('Similarity man/king:', cosine(vecs[0], vecs[2]))"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
