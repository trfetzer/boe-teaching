{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Embedding Illustration with mxbai-embed-large\n\n**Purpose**: Obtain embeddings for a few words and project them to 2D.\n\n**Dependencies**: `requests`, `numpy`, `matplotlib`\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport requests\n\nsimulate = True"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "words = ['man', 'woman', 'king', 'queen']\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def embed(text):\n    if simulate:\n        rng = {\n            'man': [1, 0, 0],\n            'woman': [1, 1, 0],\n            'king': [2, 0, 1],\n            'queen': [2, 1, 1]\n        }\n        return np.array(rng[text])\n    payload = {'model': 'mxbai-embed-large', 'prompt': text}\n    r = requests.post('http://localhost:11434/api/embeddings', json=payload)\n    r.raise_for_status()\n    return np.array(r.json()['embedding'])"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "vecs = np.vstack([embed(w) for w in words])\n# simple 2D projection\nproj = vecs[:, :2]\nfor w, p in zip(words, proj):\n    plt.scatter(p[0], p[1])\n    plt.text(p[0]+0.02, p[1]+0.02, w)\nplt.show()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from numpy.linalg import norm\n\ndef cosine(u,v):\n    return np.dot(u,v)/(norm(u)*norm(v))\n\nprint('Similarity man/king:', cosine(vecs[0], vecs[2]))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
