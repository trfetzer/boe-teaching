{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Image Classification: Count and Gender Detection\n\n**Purpose**: Use a vision-enabled model to count people in an image and guess their gender.\n\n**Dependencies**: `openai`, `base64`\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import base64\nimport json\nfrom openai import OpenAI\nclient = OpenAI(base_url=\"http://0.0.0.0:11434/v1\", api_key=\"ollama\")"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# tiny 1x1 png just for demonstration\nimg_b64 = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII='"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def analyze_image(image_b64, model=\"llava\"):\n    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Count people and detect gender\"}, {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/png;base64,\" + image_b64}}]}]\n    response = client.chat.completions.create(model=model, messages=messages)\n    return json.loads(response.choices[0].message.content)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "result = analyze_image(img_b64)\nprint(result)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
