{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Image Classification: Count and Gender Detection\n\n**Purpose**: Use a vision-enabled model to count people in an image and guess their gender.\n\n**Dependencies**: `ollama`, `pydantic`, `base64`\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import base64\nfrom pydantic import BaseModel\nimport ollama\n\nclass ImageDescription(BaseModel):\n    count: int\n    gender: list[str]\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# tiny 1x1 png just for demonstration\nimg_b64 = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNkYAAAAAYAAjCB0C8AAAAASUVORK5CYII='"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def analyze_image(image_b64, model=\"llava\"):\n    message = {\n        'role': 'user',\n        'content': 'Count people and detect gender',\n        'images': [image_b64]\n    }\n    response = ollama.chat(model=model, messages=[message], format=\"json\")\n    return ImageDescription.model_validate_json(response['message']['content'])\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "result = analyze_image(img_b64)\nprint(result.model_dump())\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
